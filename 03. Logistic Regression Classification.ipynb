{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Logistic Regression Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will use a first learning algorithm which is Logistic Regression. We are not going to recall all the math and logic behind this learning method. We are going to apply it to the training model in order to find the best predictive model, then test our model with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Boarding_C</th>\n",
       "      <th>Boarding_Q</th>\n",
       "      <th>Boarding_S</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch     Fare  Gender  Boarding_C  Boarding_Q  Boarding_S  \\\n",
       "0      0      0  13.0000       0           0           0           1   \n",
       "1      1      0  16.1000       0           0           0           1   \n",
       "2      0      0  30.6958       1           1           0           0   \n",
       "3      1      1  24.1500       1           0           0           1   \n",
       "4      0      0   7.2292       1           1           0           0   \n",
       "\n",
       "         Age  Pclass_1  Pclass_2  Pclass_3  Survived  \n",
       "0  24.000000         0         1         0         0  \n",
       "1  21.750000         0         0         1         1  \n",
       "2  56.000000         1         0         0         0  \n",
       "3  36.000000         0         0         1         0  \n",
       "4  26.507589         0         0         1         0  "
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the training dataset\n",
    "data_train = pd.read_csv('./data/training_dataset.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711 entries, 0 to 710\n",
      "Data columns (total 12 columns):\n",
      "SibSp         711 non-null int64\n",
      "Parch         711 non-null int64\n",
      "Fare          711 non-null float64\n",
      "Gender        711 non-null int64\n",
      "Boarding_C    711 non-null int64\n",
      "Boarding_Q    711 non-null int64\n",
      "Boarding_S    711 non-null int64\n",
      "Age           711 non-null float64\n",
      "Pclass_1      711 non-null int64\n",
      "Pclass_2      711 non-null int64\n",
      "Pclass_3      711 non-null int64\n",
      "Survived      711 non-null int64\n",
      "dtypes: float64(2), int64(10)\n",
      "memory usage: 66.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the testing dataset\n",
    "data_test = pd.read_csv('./data/testing_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Now getting X and Y for both the datasets\n",
    "#\n",
    "# Training dataset\n",
    "X = data_train.drop(['Survived'], axis = 1)\n",
    "Y = data_train['Survived']\n",
    "#\n",
    "# Testing dataset\n",
    "X_test = data_test.drop(['Survived'], axis = 1)\n",
    "Y_test = data_test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Logistic Regression on the Whole Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first use of Logistic Regression using `sklearn`, we are going to use the full dataset to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "Y_hat = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0]\n",
      "[0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print Y_hat[:20] # First 10 predictions...\n",
    "print Y[:20].values # ... compared to real outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which seems good. Now the scores of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score = 0.808720\n",
      "Test score = 0.792135\n"
     ]
    }
   ],
   "source": [
    "print \"Train score = %f\" % lr.score(X, Y)\n",
    "print \"Test score = %f\" % lr.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 18],\n",
       "       [19, 50]])"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72992700729927007"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the learning model from the training dataset has a good score but performs badly on the testing dataset. We can try a more robust methodology by performing a k-fold cross-validation on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Building k Logistic Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create _k_ different models (based on different datasets) and perform a voting on the final prediction. Here _k_ is unknown and should be selected by the algorithm to maximize good predictions. We are going to split the data into a test dataset, and a cross-validation dataset to find the ultimate _k_, and then, the k-different models.\n",
    "\n",
    "To do so, let's build a class that have the same syntaxe of any `sklearn` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The k Logistic Regression models algorithm\n",
    "class KLR(object):\n",
    "    \n",
    "    def __init__(self, min_k = 2, max_k = 30):\n",
    "        self.min_k = min_k\n",
    "        self.max_k = max_k\n",
    "        self.optimum_k = 0\n",
    "        self.models = []\n",
    "        self.best_validation_score = 0\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        for k in np.arange(self.min_k, (self.max_k + 1)):\n",
    "            current_validation_scores = []\n",
    "            current_models = []\n",
    "            \n",
    "            # Collect validation score and model of each fold\n",
    "            for train_indexes, validation_indexes in KFold(len(X), n_folds = k):\n",
    "                model = LogisticRegression()\n",
    "                model.fit(X[train_indexes], Y[train_indexes])\n",
    "                \n",
    "                current_validation_scores.append( model.score(X[validation_indexes], Y[validation_indexes]) )\n",
    "                current_models.append( model )\n",
    "            \n",
    "            # Decide to update score, model and optimal-k if the validation score is improved\n",
    "            if np.mean(current_validation_scores) > self.best_validation_score:\n",
    "                self.best_validation_score = np.mean(current_validation_scores)\n",
    "                self.models = current_models\n",
    "                self.optimum_k = k\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = [model.predict(X) for model in self.models]\n",
    "        \n",
    "        sum_predictions = predictions[0]\n",
    "        for i in np.arange(1, len(predictions)):\n",
    "            sum_predictions = sum_predictions + predictions[i]\n",
    "\n",
    "        return (sum_predictions >= (self.optimum_k / 2.)).astype(int)\n",
    "        # This simulates the majority voting\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        return np.mean([model.score(X, Y) for model in self.models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build KLR model using the whole training dataset\n",
    "# Remember that the KLR algorithm will internally perform Cross Validation to select the optimal k\n",
    "klr = KLR()\n",
    "klr.fit(X.values, Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the optimal k?\n",
    "klr.optimum_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0]\n",
      "[0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# First 20 predictions vs real values (0: died, 1: survived)\n",
    "print klr.predict(X_test.values)[:20]\n",
    "print Y_test.values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80604460093896724"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the mean validation score for optimal k?\n",
    "klr.best_validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80759493670886084"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the training score of the model?\n",
    "klr.score(X.values, Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78764044943820222"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the testing score of the model?\n",
    "klr.score(X_test.values, Y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, averaging many logistic regression built with the same training dataset decreased our scoring for both training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we tried to predict the passengers survival using Logistic Regression learning model.\n",
    "\n",
    "We performed quite good approximations with this methodology, when the whole training dataset was used to build the model. We also tried a more complexe variation of LR by building many LR models and averaging results. Unfortunately, this increase in complexity led to worse predictions.\n",
    "\n",
    "In the next chapters, we will try more complex learning algorithms, starting with kNN classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
